{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "- \"data/DB_Indicators.xlsx\" => World Bank's economics indicators  \n",
    "The last 5 rows are footer, so they will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/DB_Indicators.xlsx\")[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers by existing values\n",
    "1. If 2017 is NaN, fill it with 2018's values\n",
    "2. If 2018 is NaN, fill it with 2017's values\n",
    "3. If 2019 is NaN, fill it with the mean of 2017 & 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"2017\"].isnull(), \"2017\"] = df[\"2018\"]\n",
    "df.loc[df[\"2018\"].isnull(), \"2018\"] = df[\"2017\"]\n",
    "df.loc[df[\"2019\"].isnull(), \"2019\"] = (df[\"2017\"] + df[\"2018\"]) /2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the mean with values from 2017 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Mean\"] = df.mean(numeric_only=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./\"\n",
    "file_name = \"cleaned_DB_Indicators.xlsx\"\n",
    "full_directory_path = directory_path + file_name\n",
    "writer = pd.ExcelWriter(full_directory_path, engine=\"xlsxwriter\")\n",
    "df.to_excel(writer, sheet_name=\"World Indicator\", index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract column names and countries name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_name = df[\"Series Name\"][0:14].to_list()\n",
    "countries_name = df[\"Country Name\"][::14].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extact each 14 data of a country into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    data.append(row[\"Mean\"])\n",
    "    \n",
    "    if (index+1) % 14 == 0 and index != 0:\n",
    "        rows.append(data)\n",
    "        data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated = pd.DataFrame(data=rows, index=countries_name, columns=series_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./\"\n",
    "file_name = \"aggregated_DB_Indicators.xlsx\"\n",
    "full_directory_path = directory_path + file_name\n",
    "writer = pd.ExcelWriter(full_directory_path, engine=\"xlsxwriter\")\n",
    "df_aggregated.to_excel(writer, sheet_name=\"World Indicator\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "- \"data/DB_Nutrition.xlsx\" => World Bank's healtlh indicators  \n",
    "The last 5 rows are footer, so they will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.read_excel(\"data/DB_Nutrition.xlsx\")[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.loc[df[\"2017\"].isnull(), \"2017\"] = df[\"2018\"]\n",
    "df_n.loc[df[\"2018\"].isnull(), \"2018\"] = df[\"2017\"]\n",
    "df_n.loc[df[\"2019\"].isnull(), \"2019\"] = (df[\"2017\"] + df[\"2018\"]) /2\n",
    "df_n[\"Mean\"] = df.mean(numeric_only=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition_series_name = df_n[\"Series Name\"][:9].to_list()\n",
    "nutrition_countries_name = df_n[\"Country Name\"][::9].to_list()\n",
    "nutrition_countries_name == countries_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "data = []\n",
    "for index, row in df_n.iterrows():\n",
    "    data.append(row[\"Mean\"])\n",
    "    \n",
    "    if (index+1) % 9 == 0 and index != 0:\n",
    "        rows.append(data)\n",
    "        data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_n = pd.DataFrame(data=rows, index=countries_name, columns=nutrition_series_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_result = pd.concat([df_aggregated, df_aggregated_n], axis=1, join=\"inner\")\n",
    "\n",
    "# These columns are all null\n",
    "columns_to_be_dropped = [\n",
    "    \"Current health expenditure (% of GDP)\",\n",
    "    \"Domestic general government health expenditure per capita, PPP (current international $)\",\n",
    "    \"Nitrous oxide emissions (thousand metric tons of CO2 equivalent)\",\n",
    "    \"Rail lines (total route-km)\", # only 67 are un-null\n",
    "]\n",
    "aggregated_result.drop(columns_to_be_dropped, axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./\"\n",
    "file_name = \"aggregated_all.xlsx\"\n",
    "full_directory_path = directory_path + file_name\n",
    "writer = pd.ExcelWriter(full_directory_path, engine=\"xlsxwriter\")\n",
    "aggregated_result.to_excel(writer, sheet_name=\"All indicators\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed = pd.read_csv(\"data/confirmed_cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_index = df_confirmed.loc[df_confirmed[\"Province\"] == \"Hong Kong\"]\n",
    "macau_index = df_confirmed.loc[df_confirmed[\"Province\"] == \"Macau\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hong Kong and Macau shall be seperated from China in the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed.loc[hk_index.index, \"Country\"] = \"Hong Kong SAR, China\"\n",
    "df_confirmed.loc[macau_index.index, \"Country\"] = \"Macao SAR, China\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed[\"Total Confirmed\"] = df_confirmed.groupby([\"Country\"])[\"Confirmed\"].transform(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_confirmed.drop_duplicates(\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_c[\"Province\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_c[\"Confirmed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Death cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_death = pd.read_csv(\"data/death_cases.csv\")\n",
    "hk_index = df_death.loc[df_death[\"Province\"]==\"Hong Kong\"]\n",
    "macau_index = df_death.loc[df_death[\"Province\"]==\"Macau\"]\n",
    "\n",
    "df_death.loc[hk_index.index, \"Country\"] = \"Hong Kong SAR, China\"\n",
    "df_death.loc[macau_index.index, \"Country\"]=\"Macao SAR, China\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_death[\"Total Death\"]=df_death.groupby([\"Country\"])[\"Death\"].transform(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = df_death.drop_duplicates(\"Country\")\n",
    "del df_d[\"Province\"]\n",
    "del df_d[\"Death\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_cases = pd.merge(df_c, df_d, on=\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_cases = aggregated_cases.set_index(keys=aggregated_cases[\"Country\"], drop=True)\n",
    "del aggregated_cases[\"Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_diff = set(countries_name) - set(aggregated_cases[\"Country\"])\n",
    "# draft_df = pd.DataFrame([countries_name, aggregated_cases[\"Country\"], sorted(list(country_diff))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize country names in two DataFrame\n",
    "aggregated_result / aggregrated_cases\n",
    "13. Bahamas, The / **Bahamas**\n",
    "44. Congo, Dem. Rep. / **Congo (Brazzaville)**\n",
    "45. Congo, Rep. / **Congo (Kinshasa)**\n",
    "52. **Czech Republic** / Czechia\n",
    "58. Eygpt, Arab Rep. / **Eygpt**\n",
    "71. Gambia, The / **Gambia**\n",
    "91. Iran, Islamic Rep. / **Iran**\n",
    "104. Korea, Rep. / **Korea, South**\n",
    "107. **Kyrgyz Republic** / Kyrgyzstan\n",
    "108. Lao PDR / **Laos**\n",
    "161. Russian Federation / **Russia**\n",
    "173. **Slovak Republic** / Slovakia\n",
    "181. **St. Kitts and Nevis** / Saint Kitts and Nevis\n",
    "182. **St. Lucia** / Saint Lucia\n",
    "184. **St. Vincent and the Grenadines** / Saint Vincent and the Grenadines\n",
    "189. Syrian Arab Republic / **Syria**\n",
    "206. **United States** / US\n",
    "210. Venezuela, RB / Venezula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {\n",
    "    \"Bahamas, The\": \"Bahamas\",\n",
    "    \"Congo, Demp. Rep\": \"Congo (Brazzaville)\",\n",
    "    \"Congo, Rep.\": \"Congo (Kinshasa)\",\n",
    "    \"Eygpt, Arab Rep.\": \"Eygpt\",\n",
    "    \"Gambia, The\": \"Gambia\",\n",
    "    \"Iran, Islamic Rep.\": \"Iran\",\n",
    "    \"Korea, Rep.\": \"Korea, South\",\n",
    "    \"Lao PDR\": \"Laos\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Syrian Arab Republic\": \"Syria\",\n",
    "    \"Venezuela, RB\": \"Venezula\",\n",
    "}\n",
    "\n",
    "aggregated_result.rename(index=result_dict, inplace=True)\n",
    "\n",
    "case_dict = {\n",
    "    \"Czechia\": \"Czech Republic\",\n",
    "    \"Kyrgyzstan\": \"Kyrgyz Republic\",\n",
    "    \"Slovakia\": \"Slovak Republic\",\n",
    "    \"Saint Kitts and Nevis\": \"St. Kitts and Nevis\",\n",
    "    \"Saint Lucia\": \"St. Lucia\",\n",
    "    \"Saint Vincent and the Grenadines\": \"St. Vincent and the Grenadines\",\n",
    "    \"US\": \"United States\"\n",
    "}\n",
    "\n",
    "aggregated_cases.rename(index=case_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(aggregated_cases, aggregated_result, left_index=True, right_index=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./\"\n",
    "file_name = \"combined_all.xlsx\"\n",
    "full_directory_path = directory_path + file_name\n",
    "writer = pd.ExcelWriter(full_directory_path, engine=\"xlsxwriter\")\n",
    "combined_df.to_excel(writer, sheet_name=\"All indicators\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_combined_df = combined_df.fillna(combined_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All columns' name\n",
    "~~~\n",
    "0. 'Total Confirmed',\n",
    "1. 'Total Death',\n",
    "2. 'Adjusted net national income per capita (current US$)',\n",
    "3. 'UHC service coverage index',\n",
    "4. 'International tourism, number of arrivals',\n",
    "5. 'Fixed broadband subscriptions (per 100 people)',\n",
    "6. 'Fixed telephone subscriptions (per 100 people)',\n",
    "7. 'Mobile cellular subscriptions (per 100 people)',\n",
    "8. 'PM2.5 air pollution, mean annual exposure (micrograms per cubic meter)',\n",
    "9. 'Population density (people per sq. km of land area)',\n",
    "10. 'Urban population (% of total population)',\n",
    "11. 'GDP per capita (current US$)',\n",
    "12. 'GNI per capita, Atlas method (current US$)',\n",
    "13. 'Literacy rate, adult total (% of people ages 15 and above)',\n",
    "14. 'Public spending on education, total (% of GDP)',\n",
    "15. 'Community health workers (per 1,000 people)',\n",
    "16. 'Number of people who are undernourished',\n",
    "17. 'Population ages 65 and above, total',\n",
    "18. 'Population ages 0-14 (% of total population)',\n",
    "19. 'People using at least basic drinking water services (% of population)',\n",
    "20. 'People practicing open defecation (% of population)']`\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_col_names = [\n",
    "    \"Total_Confirmed\",\n",
    "    \"Total_Death\",\n",
    "    \"National_Income_Per_Capital\",\n",
    "    \"UHC_Service_Coverage_Index\",\n",
    "    \"International_Tourism Arrivals\",\n",
    "    \"Fixed_Broadband_Subscriptions\",\n",
    "    \"Fixed_Telephone_Subscriptions\",\n",
    "    \"Mobile_Phone_Subscriptions\",\n",
    "    \"PM2.5_Mean_Annual_Exposure\",\n",
    "    \"Population_Density\",\n",
    "    \"Urban_Population\",   #10\n",
    "    \"GDP_Per_Capital\",\n",
    "    \"GNI_Per_Capital\",\n",
    "    \"Adult_Literacy_Rate\",\n",
    "    \"Public_Education_Expenses\",\n",
    "    \"Community_Health_Workers\",\n",
    "    \"Number_of_Undernourished\",\n",
    "    \"Population_over_65\",\n",
    "    \"Population_below_14\",\n",
    "    \"People_with_Basic_Drinking_Water\",\n",
    "    \"People_Practicing_Open_Defecation\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_combined_df.columns = sanitized_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./\"\n",
    "file_name = \"filled_combined_all.xlsx\"\n",
    "full_directory_path = directory_path + file_name\n",
    "writer = pd.ExcelWriter(full_directory_path, engine=\"xlsxwriter\")\n",
    "filled_combined_df.to_excel(writer, sheet_name=\"All indicators\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = filled_combined_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def calculate_linear_regression(dep_var, indep_var):\n",
    "    formula_str = f\"{dep_var} ~ \"\n",
    "    if len(indep_var) == 1:\n",
    "        formula_str += indep_var[0][0]\n",
    "    else:\n",
    "        s = \" + \".join(indep_var)\n",
    "        formula_str += s\n",
    "        \n",
    "    print(formula_str)\n",
    "    \n",
    "    result = smf.ols(\n",
    "        formula=formula_str,\n",
    "        data=filled_combined_df\n",
    "    ).fit()\n",
    "    \n",
    "    print(f\"R Square: {result.rsquared}\\nP Values: \\n{result.pvalues}\")\n",
    "    \n",
    "\n",
    "# calculate_linear_regression(cols[1], [cols[2], cols[3]])\n",
    "\n",
    "    \n",
    "    \n",
    "# result = smf.ols(\n",
    "#     formula=f\"{cols[1]} ~ {cols[2]}\",\n",
    "#     data=filled_combined_df\n",
    "# ).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a',), ('b',), ('c',), ('d',), ('e',), ('f',), ('g',), ('h',), ('i',), ('j',), ('k',), ('l',), ('m',), ('n',), ('o',), ('p',), ('q',), ('r',), ('s',), ('t',), ('u',)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-f8728e1ce048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomb_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcalculate_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-bbfe6b4c6527>\u001b[0m in \u001b[0;36mcalculate_linear_regression\u001b[0;34m(dep_var, indep_var)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mformula_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mindep_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" + \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindep_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mformula_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, tuple found"
     ]
    }
   ],
   "source": [
    "formula_str = []\n",
    "r_sqr = []\n",
    "p_val = []\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "for arg in range(1, 3):\n",
    "    comb_list = list(combinations(cols, arg))\n",
    "    print(comb_list)\n",
    "    \n",
    "    for comb in comb_list:\n",
    "        calculate_linear_regression(cols[1], comb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
